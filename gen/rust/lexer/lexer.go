/*
Copyright 2020 Marius Ackerman

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

// Package lexer generates a Rust lexer
package lexer

import (
	"bytes"
	"fmt"
	"text/template"

	"github.com/goccmack/gogll/ast"
	"github.com/goccmack/gogll/im/tokens"
	"github.com/goccmack/gogll/lex/items"
	"github.com/goccmack/gogll/util/runeset"
	"github.com/goccmack/goutil/ioutil"
	"github.com/goccmack/goutil/stringset"
)

type Data struct {
	Package string
	Accept  []string
	// A slice of transitions for each set
	Transitions    [][]*Transition
	CodeBlockDelim string
}

type Transition struct {
	Condition string
	NextState int
}

func Gen(fname string, g *ast.GoGLL, ls *items.Sets, ts *tokens.Tokens) {
	tmpl, err := template.New("Rust lexer").Parse(tmplSrc)
	if err != nil {
		panic(err)
	}
	buf := new(bytes.Buffer)
	if err = tmpl.Execute(buf, getData(g, ls, ts)); err != nil {
		panic(err)
	}
	if err = ioutil.WriteFile(fname, buf.Bytes()); err != nil {
		panic(err)
	}
}

// slits is the set of StringLiterals from the AST
func getAccept(ls *items.Sets, ts *tokens.Tokens, slits *stringset.StringSet) (tokTypes []string) {
	for _, s := range ls.Sets() {
		tok := s.Accept(slits)
		tokTypes = append(tokTypes, ts.LiteralToString[tok])
	}
	return
}

func getData(g *ast.GoGLL, ls *items.Sets, ts *tokens.Tokens) *Data {
	return &Data{
		Package:        g.Package.GetString(),
		Accept:         getAccept(ls, ts, g.GetStringLiteralsSet()),
		Transitions:    getTransitions(ls),
		CodeBlockDelim: "```",
	}
}

func getTransitions(ls *items.Sets) [][]*Transition {
	trans := make([][]*Transition, len(ls.Sets()))
	for i, set := range ls.Sets() {
		trans[i] = getSetTransitions(set)
	}
	return trans
}

func getSetTransitions(set *items.Set) []*Transition {
	trans := make([]*Transition, len(set.Transitions))
	for i, t := range set.Transitions {
		trans[i] = getTransition(t)
	}
	return trans
}

func getTransition(t *items.Transition) *Transition {
	return &Transition{
		Condition: getCondition(t.Event),
		NextState: t.To.No,
	}
}

func getCondition(event ast.LexBase) string {
	switch e := event.(type) {
	case *ast.Any:
		return "true"
	case *ast.AnyOf:
		return fmt.Sprintf("any(c, %s)", toVec(e.Set))
	case *ast.CharLiteral:
		return fmt.Sprintf("c == %s", string(e.Literal))
	case *ast.Not:
		return fmt.Sprintf("not(c, %s)", toVec(e.Set))
	case *ast.UnicodeClass:
		switch e.Type {
		case ast.Letter:
			return "c.is_alphabetic()"
		case ast.Upcase:
			return "c.is_uppercase()"
		case ast.Lowcase:
			return "c.is_lowercase()"
		case ast.Number:
			return "c.is_numeric()"
		case ast.Space:
			return "c.is_whitespace()"
		}
		panic(fmt.Sprintf("Invalid type %d", e.Type))
	}
	panic(fmt.Sprintf("Invalid event %T", event))
}

func escape(c rune) string {
	switch c {
	case '\'':
		return "\\'"
	case '\\':
		return "\\\\"
	case '\r':
		return "\\r"
	case '\n':
		return "\\n"
	case '\t':
		return "\\t"
	}
	return string(c)
}

func toVec(rs *runeset.RuneSet) string {
	w := new(bytes.Buffer)
	fmt.Fprint(w, "&vec![")
	for i, r := range rs.Elements() {
		if i > 0 {
			fmt.Fprint(w, ",")
		}
		fmt.Fprintf(w, "'%s'", escape(r))
	}
	fmt.Fprint(w, "]")
	return w.String()
}

const tmplSrc = `
//! Module lexer is generated by GoGLL. Do not edit.

extern crate lazy_static;

use crate::token;

use std::{fs, io};
use std::rc::Rc;
use lazy_static::lazy_static;

type State = usize;

const NULL_STATE: State = usize::MAX ;

/**
Lexer contains both the input Vec<char> and the Vec<token::Token>
parsed from the input
*/
pub struct Lexer {
	/// i is the input vector of char
	i: Rc<Vec<char>>,

	/// tokens is the vector of tokens constructed by the lexer from I
	pub tokens: Vec<Rc<token::Token>>
}

impl Lexer {
	/**
	new_file constructs a Lexer created from the input file, fname. 

	If the input file is a markdown file new_file process treats all text outside
	code blocks as whitespace. All text inside code blocks are treated as input text.

	If the input file is a normal text file new_file treats all text in the inputfile
	as input text.
	*/
	#[allow(dead_code)]
	pub fn new_file(fname: &String) -> io::Result<Box<Lexer>> {
		let i = Rc::new(load_file(fname)?);
		Ok(Lexer::new(i))
	}

	/**
	new constructs a Lexer from a Vec<char>. 
	
	All contents of the input are treated as input text.
	*/
	pub fn new(input: Rc<Vec<char>>) -> Box<Lexer> {
		let mut lex = Box::new(Lexer{
			i:      input.clone(),
			tokens: Vec::new(),
		});
		let mut lext = 0;
		while lext < lex.i.len() {
			while lext < lex.i.len() && lex.i[lext].is_whitespace() {
				lext += 1
			}
			if lext < lex.i.len() {
				let tok = lex.scan(lext);
				lext = tok.rext;
				lex.add_token(tok)
			}
		}
		lex.add(token::Type::EOF, input.len(), input.len());
		lex
	}

	fn add(&mut self, t: token::Type, lext: usize, rext: usize) {
		self.add_token(token::new(t, lext, rext, &self.i))
	}
	
	fn add_token(&mut self, tok: Rc<token::Token>) {
		self.tokens.push(tok)
	}
	
	fn scan(&mut self, i: usize) -> Rc<token::Token> {
		let mut s: State = 0;
		let mut typ = token::Type::Error;
		let mut rext = i;

		while s != NULL_STATE {
			if rext >= self.i.len() {
				typ = ACCEPT[s];
				s = NULL_STATE
			} else {
				typ = ACCEPT[s];
				s = NEXT_STATE[s](self.i[rext]);
				if s != NULL_STATE || typ == token::Type::Error {
					rext += 1
				}
			}
		}
		return token::new(typ, i, rext, &self.i)
	}

	/// get_line_column returns the (line, column) of char[i] in the input
	#[allow(dead_code)]
	pub fn get_line_column(&self, i: usize) -> (usize, usize) {
		let mut line = 1;
		let mut col = 1;
		let mut j = 0;
		while j < i {
			match self.i[j] {
			'\n' => {
				line += 1;
				col = 1
			},
			'\t' => col += 4,
			_ => col += 1
			}
			j += 1
		}
		(line, col)
	}
	
	/// get_line_column_of_token returns the (line, column) of token[i] 
	/// in the input
	#[allow(dead_code)]
	pub fn get_line_column_of_token(&self, i: usize) -> (usize, usize) {
		self.get_line_column(self.tokens[i].lext)
	}

	// get_string returns the input string from the left extent of Token[lext] to
	// the right extent of Token[rext]
	#[allow(dead_code)]
	pub fn get_string(&self, lext: usize, rext: usize) -> String {
		let lext = self.tokens[lext].lext;
		let rext = self.tokens[rext].rext;
		self.i[lext..rext].iter().collect::<String>()
	}
	
	}
/*** End of Lexer implementation ***/


fn load_file(fname: &String) -> io::Result<Vec<char>> {
	let input = fs::read_to_string(fname)?;
	let input: Vec<char> = input.chars().collect();
	if fname.ends_with(".md") {
		load_md(input)
	} else {
		Ok(input)
	}
}

fn load_md(input: Vec<char>) -> io::Result<Vec<char>> {
    let mut i = 0;
    let mut output: Vec<char> = Vec::new();
    let mut text = true;
    while i < input.len() {
        if i < input.len() - 3
            && input[i..i + 3].into_iter().collect::<String>() == String::from("{{.CodeBlockDelim}}")
        {
            text = !text;
            output.append(&mut "   ".chars().collect());
            i += 3;
        }
        if i < input.len() {
            if text {
                match input[i] {
                    '\n' => output.push('\n'),
                    _ => output.push(' '),
                }
            } else {
                output.push(input[i]);
            }
            i += 1;
        }
    }
	Ok(output)
}

#[allow(dead_code)]
fn any(r: char, set: &Vec<char>) -> bool {
	for r1 in set.iter() {
		if &r == r1 {
			return true
		}
	}
	return false
}

#[allow(dead_code)]
fn not(r: char, set: &Vec<char>) -> bool {
	for r1 in set.iter() {
		if &r == r1 {
			return false
		}
	}
	return true
}

lazy_static! {
	static ref ACCEPT: Vec<token::Type> = vec![ {{range $tok := .Accept}}
		token::Type::{{$tok}}, {{end}}
	];
}

lazy_static! {
	static ref NEXT_STATE: Vec<fn(char) -> State> = vec![  {{range $i, $set := .Transitions}}
	// Set{{$i}} {{if (len $set)}}
	|c| -> State { {{ else }}
	|_| -> State { {{end}}
		match true { {{range $cond := $set}}
			_ if {{$cond.Condition}} => return {{$cond.NextState}}, {{end}}
			_ => NULL_STATE
		}
	}, {{end}}
	];
}
`
